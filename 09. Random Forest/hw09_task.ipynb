{"cells":[{"cell_type":"markdown","metadata":{"id":"kxs2-KrwXHIJ"},"source":["# Случайные леса\n","__Суммарное количество баллов: 10__\n","\n","__Решение отправлять на `ml.course.practice@gmail.com`__\n","\n","__Тема письма: `[HSE][ML][MS][HW09] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n","\n","В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным пользователей социальной сети Вконтакте, и сравнить его эффективность с ансамблем, предоставляемым библиотекой CatBoost.\n","\n","В результате мы сможем определить, какие подписки пользователей больше всего влияют на определение возраста и пола человека. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igibYsAlXHIN"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import copy\n","from catboost import CatBoostClassifier"]},{"cell_type":"markdown","metadata":{"id":"NL0piKVuXHIP"},"source":["### Задание 1 (2 балла)\n","Random Forest состоит из деревьев решений. Каждое такое дерево строится на одной из выборок, полученных при помощи bagging. Элементы, которые не вошли в новую обучающую выборку, образуют out-of-bag выборку. Кроме того, в каждом узле дерева мы случайным образом выбираем набор из `max_features` и ищем признак для предиката разбиения только в этом наборе.\n","\n","Сегодня мы будем работать только с бинарными признаками, поэтому нет необходимости выбирать значение признака для разбиения.\n","\n","#### Методы\n","`predict(X)` - возвращает предсказанные метки для элементов выборки `X`\n","\n","#### Параметры конструктора\n","`X, y` - обучающая выборка и соответствующие ей метки классов. Из нее нужно получить выборку для построения дерева при помощи bagging. Out-of-bag выборку нужно запомнить, она понадобится потом.\n","\n","`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n","\n","`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n","\n","`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n","\n","`max_features=\"auto\"` - количество признаков, которые могут использоваться в узле. Если `\"auto\"` - равно `sqrt(X.shape[1])`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3nZDhW3XHIO"},"outputs":[],"source":["def gini(x):\n","    pass\n","    \n","def entropy(x):\n","    pass\n","\n","def gain(left_y, right_y, criterion):\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gShAKrgXHIQ"},"outputs":[],"source":["class DecisionTree:\n","    def __init__(self, X, y, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\"):\n","        raise NotImplementedError()\n","        \n","    def predict(self, X):\n","        raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"id":"QbfDFicaXHIQ"},"source":["### Задание 2 (2 балла)\n","Теперь реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание.\n","\n","#### Параметры конструктора\n","`n_estimators` - количество используемых для предсказания деревьев.\n","\n","Остальное - параметры деревьев.\n","\n","#### Методы\n","`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n","\n","`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8KtlmvBXHIR"},"outputs":[],"source":["class RandomForestClassifier:\n","    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", n_estimators=10):\n","        raise NotImplementedError()\n","    \n","    def fit(self, X, y):\n","        raise NotImplementedError()\n","    \n","    def predict(self, X):\n","        raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"id":"b41Wii0_XHIR"},"source":["### Задание 3 (2 балла)\n","Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest - посчитать out-of-bag ошибку предсказания `err_oob`, а затем перемешать значения признака `j` и посчитать ее (`err_oob_j`) еще раз. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n","\n","Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SEa85EniXHIS"},"outputs":[],"source":["def feature_importance(rfc):\n","    raise NotImplementedError()\n","\n","def most_important_features(importance, names, k=20):\n","    # Выводит названия k самых важных признаков\n","    idicies = np.argsort(importance)[::-1][:k]\n","    return np.array(names)[idicies]"]},{"cell_type":"markdown","metadata":{"id":"w4VS3WDyXHIT"},"source":["Наконец, пришло время протестировать наше дерево на простом синтетическом наборе данных. В результате точность должна быть примерно равна `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDbhPFWIXHIT"},"outputs":[],"source":["def synthetic_dataset(size):\n","    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n","          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n","    y = [i % 3 for i in range(size)]\n","    return np.array(X), np.array(y)\n","\n","X, y = synthetic_dataset(1000)\n","rfc = RandomForestClassifier(n_estimators=100)\n","rfc.fit(X, y)\n","print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n","print(\"Importance:\", feature_importance(rfc))"]},{"cell_type":"markdown","metadata":{"id":"JQSKeGmoXHIT"},"source":["### Задание 4 (1 балл)\n","Теперь поработаем с реальными данными.\n","\n","Выборка состоит из публичных анонимизированных данных пользователей социальной сети Вконтакте. Первые два столбца отражают возрастную группу (`zoomer`, `doomer` и `boomer`) и пол (`female`, `male`). Все остальные столбцы являются бинарными признаками, каждый из них определяет, подписан ли пользователь на определенную группу/публичную страницу или нет.\\\n","\\\n","Необходимо обучить два классификатора, один из которых определяет возрастную группу, а второй - пол.\\\n","\\\n","Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются. Лес должен строиться за какое-то разумное время."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xA1GfFJMXHIU"},"outputs":[],"source":["def read_dataset(path):\n","    dataframe = pandas.read_csv(path, header=0)\n","    dataset = dataframe.values.tolist()\n","    random.shuffle(dataset)\n","    y_age = [row[0] for row in dataset]\n","    y_sex = [row[1] for row in dataset]\n","    X = [row[2:] for row in dataset]\n","    \n","    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYKHUy7gXHIU"},"outputs":[],"source":["X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n","X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"]},{"cell_type":"markdown","metadata":{"id":"eKVys5RMXHIU"},"source":["#### Возраст"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LYUV5yZHXHIU"},"outputs":[],"source":["rfc = RandomForestClassifier(n_estimators=10)\n","\n","rfc.fit(X_train, y_age_train)\n","print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_age_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n","    print(str(i+1) + \".\", name)"]},{"cell_type":"markdown","metadata":{"id":"wJuzLuVYXHIV"},"source":["#### Пол"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBGU4dQ_XHIV"},"outputs":[],"source":["rfc = RandomForestClassifier(n_estimators=10)\n","rfc.fit(X_train, y_sex_train)\n","print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_sex_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n","    print(str(i+1) + \".\", name)"]},{"cell_type":"markdown","metadata":{"id":"zOO-Lk_0XHIV"},"source":["### CatBoost\n","В качестве аьтернативы попробуем CatBoost. \n","\n","Устаниовить его можно просто с помощью `pip install catboost`. Туториалы можно найти, например, [здесь](https://catboost.ai/docs/concepts/python-usages-examples.html#multiclassification) и [здесь](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb). Главное - не забудьте использовать `loss_function='MultiClass'`.\\\n","\\\n","Сначала протестируйте CatBoost на синтетических данных. Выведите точность и важность признаков."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mWBdHNJPXHIV"},"outputs":[],"source":["X, y = synthetic_dataset(1000)\n","print(\"Accuracy:\", np.mean(None == y))\n","print(\"Importance:\", None)"]},{"cell_type":"markdown","metadata":{"id":"sj8GnxA7XHIW"},"source":["### Задание 5 (3 балла)\n","Попробуем применить один из используемых на практике алгоритмов. В этом нам поможет CatBoost. Также, как и реализованный ними RandomForest, применим его для определения пола и возраста пользователей сети Вконтакте, выведите названия наиболее важных признаков так же, как в задании 3.\\\n","\\\n","Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HtjJ0jc8XHIW"},"outputs":[],"source":["X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n","X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n","X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"]},{"cell_type":"markdown","metadata":{"id":"HxkWgk-VXHIW"},"source":["#### Возраст"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNzGCe8kXHIW"},"outputs":[],"source":["print(\"Accuracy:\", np.mean(None == y_age_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(None, features, 10)):\n","    print(str(i+1) + \".\", name)"]},{"cell_type":"markdown","metadata":{"id":"xIssDLRaXHIW"},"source":["#### Пол"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWPSbmKqXHIX"},"outputs":[],"source":["print(\"Accuracy:\", np.mean(None == y_sex_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(None, features, 10)):\n","    print(str(i+1) + \".\", name)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"hw09_task.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}